# ğŸ¦ AnÃ¡lise de CrÃ©dito com AplicaÃ§Ã£o Web

Uma aplicaÃ§Ã£o completa de Machine Learning para anÃ¡lise de risco de crÃ©dito, implementada com arquitetura em 3 camadas: banco de dados PostgreSQ### **ğŸ³ ExecuÃ§Ã£o com Docker (Recomendado para ProduÃ§Ã£o)**

#### **PrÃ©-requisitos Docker:**
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) instalado
- 4GB RAM disponÃ­vel para containers
- 2GB espaÃ§o em disco

#### **Setup AutomÃ¡tico com Docker:**
```powershell
# Verificar se Docker estÃ¡ funcionando
python docker-manager.py check

# Setup completo automÃ¡tico (build + start + health check)
python docker-manager.py full

# Ou manualmente:
docker-compose build
docker-compose up -d

# Verificar status dos serviÃ§os
python docker-manager.py health
```

#### **Gerenciamento de Containers:**
```powershell
# Parar todos os serviÃ§os
python docker-manager.py stop
# ou
docker-compose down

# Reiniciar serviÃ§os
python docker-manager.py restart

# Ver logs em tempo real
python docker-manager.py logs
# ou
docker-compose logs -f

# Verificar saÃºde dos serviÃ§os
python docker-manager.py health
```

#### **Acessar AplicaÃ§Ãµes Docker:**
- ğŸ¦ **App Principal**: http://localhost:8501
- ğŸ“Š **Dashboard**: http://localhost:8502  
- ğŸ”Œ **API Health**: http://localhost:5000/health

#### **Arquitetura Docker:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Container â”‚    â”‚Streamlit Containerâ”‚    â”‚Dashboard Containerâ”‚
â”‚   Port: 5000    â”‚â”€â”€â”€â”€â”‚   Port: 8501     â”‚    â”‚   Port: 8502     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ credit_network  â”‚
                        â”‚   (Bridge)      â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
``` com modelo de rede neural, e interface web Streamlit.

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa um sistema completo de anÃ¡lise de crÃ©dito que simula o processo de avaliaÃ§Ã£o de risco em instituiÃ§Ãµes financeiras. O sistema utiliza aprendizado de mÃ¡quina para prever a probabilidade de inadimplÃªncia de clientes com base em seus dados pessoais e financeiros.

### ğŸ—ï¸ Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚â”€â”€â”€â–¶â”‚   API Flask     â”‚â”€â”€â”€â–¶â”‚  Streamlit UI   â”‚
â”‚  (Dados)        â”‚    â”‚  (ML Model)     â”‚    â”‚  (Interface)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fluxo de Dados:**
1. **ExtraÃ§Ã£o**: Dados extraÃ­dos do PostgreSQL via consulta SQL complexa
2. **Processamento**: Limpeza, feature engineering e prÃ©-processamento
3. **Modelo**: Rede neural com 4 camadas densas para classificaÃ§Ã£o binÃ¡ria  
4. **API**: Endpoint Flask que serve o modelo treinado
5. **Interface**: Streamlit para entrada de dados e visualizaÃ§Ã£o de resultados
## âš™ï¸ Funcionalidades Principais

### ğŸ¤– **Modelo de Machine Learning**
- **Arquitetura**: Rede neural com 4 camadas densas (128â†’64â†’32â†’1 neurÃ´nios)
- **TÃ©cnicas**: Dropout (30%) para evitar overfitting, otimizador Adam
- **SeleÃ§Ã£o de Features**: RFE para selecionar as 10 melhores caracterÃ­sticas
- **Performance**: ClassificaÃ§Ã£o binÃ¡ria com mÃ©tricas de precisÃ£o, recall e F1-score

### ğŸ”„ **Pipeline de Processamento de Dados**
- **Limpeza**: Tratamento de valores nulos, correÃ§Ã£o de erros de digitaÃ§Ã£o com fuzzy matching
- **Feature Engineering**: CriaÃ§Ã£o da variÃ¡vel `proporÃ§Ã£o_solicitado_total`
- **NormalizaÃ§Ã£o**: StandardScaler para variÃ¡veis numÃ©ricas
- **CodificaÃ§Ã£o**: LabelEncoder para variÃ¡veis categÃ³ricas
- **Tratamento de Outliers**: RemoÃ§Ã£o baseada em intervalos estatÃ­sticos

### ğŸŒ **API RESTful (Flask)**
- **Endpoint**: `/predict` para prediÃ§Ãµes em tempo real
- **Formato**: Recebe/retorna dados em JSON
- **PrÃ©-processamento**: AplicaÃ§Ã£o automÃ¡tica das transformaÃ§Ãµes de treino
- **Escalabilidade**: Pode ser containerizada e deployada em produÃ§Ã£o

### ğŸ’» **Interface Web Interativa (Streamlit)**
- **FormulÃ¡rio**: Campos intuitivos para entrada de dados do cliente
- **ValidaÃ§Ã£o**: Controles de entrada com valores mÃ­nimos/mÃ¡ximos
- **Resultado**: ExibiÃ§Ã£o clara de probabilidade e classificaÃ§Ã£o de risco
- **UX/UI**: Interface responsiva e user-friendly

### ğŸ” **Explicabilidade com LIME**
- **Interpretabilidade**: ExplicaÃ§Ãµes das decisÃµes do modelo
- **TransparÃªncia**: VisualizaÃ§Ã£o das features mais importantes
- **Conformidade**: Atende requisitos de explicabilidade em FinTech
- **Output**: RelatÃ³rios HTML interativos
## ğŸ› ï¸ Tecnologias Utilizadas

### **Backend & API**
- **Python 3.12.4**: Linguagem principal
- **Flask 3.0.3**: Framework para API RESTful
- **PostgreSQL**: Banco de dados relacional

### **Machine Learning**
- **TensorFlow 2.16.1 / Keras**: Framework para deep learning
- **Scikit-learn 1.4.1**: PrÃ©-processamento e avaliaÃ§Ã£o
- **NumPy 1.26.4**: OperaÃ§Ãµes numÃ©ricas
- **Pandas 2.2.1**: ManipulaÃ§Ã£o de dados

### **Frontend & VisualizaÃ§Ã£o**
- **Streamlit 1.32.1**: Interface web interativa
- **Matplotlib 3.8.3**: GrÃ¡ficos e visualizaÃ§Ãµes
- **Seaborn 0.13.2**: VisualizaÃ§Ãµes estatÃ­sticas

### **Explicabilidade & Interpretabilidade**
- **LIME 0.2.0.1**: Local Interpretable Model-agnostic Explanations
- **SHAP 0.45.0**: SHapley Additive exPlanations

### **UtilitÃ¡rios**
- **psycopg2-binary 2.9.9**: ConexÃ£o PostgreSQL
- **PyYAML 6.0.1**: ConfiguraÃ§Ãµes em YAML  
- **fuzzywuzzy 0.18.0**: CorreÃ§Ã£o de strings
- **joblib 1.3.2**: SerializaÃ§Ã£o de modelos

### **Estrutura dos Arquivos**
```
ğŸ“¦ analise_credito_com_appweb/
â”œâ”€â”€ ğŸ“„ modelcreation.py      # Treinamento do modelo ML
â”œâ”€â”€ ğŸ“„ model_mock.py         # ğŸ†• Modelo mock sklearn (Python 3.13 compatÃ­vel)
â”œâ”€â”€ ğŸ“„ api.py                # API Flask bÃ¡sica para prediÃ§Ãµes
â”œâ”€â”€ ğŸ“„ api_mock.py           # ğŸ†• API Flask com modelo mock funcionando
â”œâ”€â”€ ğŸ“„ webapp.py             # Interface Streamlit
â”œâ”€â”€ ğŸ“„ dashboard.py          # ğŸ†• Dashboard de mÃ©tricas e monitoramento
â”œâ”€â”€ ğŸ“„ xai.py                # Explicabilidade com LIME
â”œâ”€â”€ ğŸ“„ utils.py              # FunÃ§Ãµes auxiliares
â”œâ”€â”€ ğŸ“„ const.py              # Consulta SQL
â”œâ”€â”€ ğŸ“„ config.py             # ğŸ†• ConfiguraÃ§Ãµes centralizadas com variÃ¡veis de ambiente
â”œâ”€â”€ ğŸ“„ config.yaml           # ConfiguraÃ§Ãµes legadas (YAML)
â”œâ”€â”€ ğŸ“„ logger.py             # ğŸ†• Sistema de logging avanÃ§ado
â”œâ”€â”€ ğŸ“„ setup.py              # ğŸ†• Script de automaÃ§Ã£o e setup
â”œâ”€â”€ ğŸ“„ testflask.py          # Testes bÃ¡sicos da API
â”œâ”€â”€ ğŸ“„ requirements.txt      # â¬†ï¸ DependÃªncias atualizadas
â”œâ”€â”€ ğŸ“„ modelcreation.ipynb   # Notebook de desenvolvimento
â”œâ”€â”€ ğŸ“„ Dockerfile            # ğŸ†• ContainerizaÃ§Ã£o otimizada
â”œâ”€â”€ ğŸ“„ docker-compose.yml    # ğŸ†• OrquestraÃ§Ã£o de containers atualizada
â”œâ”€â”€ ğŸ“„ docker-manager.py     # ğŸ†• Gerenciador Docker automatizado
â”œâ”€â”€ ğŸ“„ docker-init.py        # ğŸ†• Script de inicializaÃ§Ã£o para containers
â”œâ”€â”€ ğŸ“„ .dockerignore         # ğŸ†• OtimizaÃ§Ã£o de build Docker
â”œâ”€â”€ ğŸ“„ .env.example          # ğŸ†• Exemplo de variÃ¡veis de ambiente
â”œâ”€â”€ ğŸ“ objects/              # Modelos e transformadores salvos
â”‚   â”œâ”€â”€ ğŸ¤– modelo_mock.joblib # Modelo sklearn treinado
â”‚   â”œâ”€â”€ ğŸ“Š scaler*.joblib    # Normalizadores (7 arquivos)
â”‚   â”œâ”€â”€ ğŸ·ï¸ labelencoder*.joblib # Codificadores (6 arquivos)
â”‚   â””â”€â”€ ğŸ¯ selector.joblib   # Seletor de features
â”œâ”€â”€ ğŸ“ logs/                 # ğŸ†• Logs do sistema
â”‚   â”œâ”€â”€ ğŸ“‹ app.log           # Log geral da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ ğŸ“Š predictions.log   # Log de prediÃ§Ãµes
â”‚   â””â”€â”€ âš¡ performance.log   # Log de performance
â””â”€â”€ ğŸ“ tests/                # ğŸ†• Testes automatizados
    â”œâ”€â”€ ğŸ§ª test_utils.py     # Testes das funÃ§Ãµes utilitÃ¡rias
    â”œâ”€â”€ ğŸ”Œ test_api.py       # Testes da API
    â””â”€â”€ ğŸ“Š test_prediction.py # Testes de prediÃ§Ã£o integrada
```
â”œâ”€â”€ ğŸ“ logs/                 # ğŸ†• Logs do sistema
â”‚   â”œâ”€â”€ ğŸ“‹ app.log           # Log geral da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ ğŸ“Š predictions.log   # Log de prediÃ§Ãµes
â”‚   â””â”€â”€ âš¡ performance.log   # Log de performance
â””â”€â”€ ğŸ“ tests/                # ğŸ†• Testes automatizados
    â”œâ”€â”€ ğŸ§ª test_utils.py     # Testes das funÃ§Ãµes utilitÃ¡rias
    â””â”€â”€ ğŸ”Œ test_api.py       # Testes da API
```

## ğŸš€ Como Executar o Projeto

### **ğŸ“‹ PrÃ©-requisitos**
- Python 3.12.4 ou superior
- PostgreSQL (opcional - configurado conforme `.env`)
- 8GB RAM recomendado para treinamento
- Docker (opcional - para containerizaÃ§Ã£o)

### **âš¡ Setup AutomÃ¡tico (Recomendado)**

1. **Clone e configure automaticamente:**
   ```powershell
   git clone https://github.com/TonFLY/analise_credito_com_appweb.git
   cd analise_credito_com_appweb
   
   # Crie o ambiente virtual
   python -m venv venv
   venv\Scripts\Activate.ps1
   
   # Instale dependÃªncias
   pip install -r requirements.txt
   
   # Execute setup completo automÃ¡tico
   python setup.py complete
   ```

2. **Acesse as aplicaÃ§Ãµes:**
   - ï¿½ **App Principal**: `http://localhost:8501`
   - ğŸ“Š **Dashboard**: `http://localhost:8502` 
   - ï¿½ **API**: `http://localhost:5000`

### **ğŸ”§ Setup Manual (AvanÃ§ado)**

#### **Passo 1: ConfiguraÃ§Ã£o do Ambiente**
```powershell
# Clone e setup bÃ¡sico
git clone https://github.com/TonFLY/analise_credito_com_appweb.git
cd analise_credito_com_appweb
python -m venv venv
venv\Scripts\Activate.ps1
pip install -r requirements.txt

# Configure variÃ¡veis de ambiente
copy .env.example .env
# Edite .env com suas configuraÃ§Ãµes
```

#### **Passo 2: Treinar o Modelo**
```powershell
python modelcreation.py
# ou usando o setup
python setup.py train
```

#### **Passo 3: Executar ServiÃ§os**

**API melhorada:**
```powershell
python api_improved.py
```

**Interface Principal:**
```powershell
streamlit run webapp.py
```

**Dashboard de MÃ©tricas:**
```powershell
streamlit run dashboard.py --server.port 8502
```

### **ï¿½ ExecuÃ§Ã£o com Docker**

```powershell
# Build e execuÃ§Ã£o completa
docker-compose up --build

# Apenas a API
docker-compose up api

# Parar todos os serviÃ§os
docker-compose down
```

### **ğŸ§ª Executando Testes**

```powershell
# Testes automatizados
python setup.py test

# ou manualmente
python -m pytest tests/ -v

# ou usando unittest
python -m unittest discover tests/ -v
```
## ğŸ¥ DemonstraÃ§Ã£o

![USO DO APLICATIVO](https://github.com/TonFLY/images/blob/main/gif.gif?raw=true)

## ğŸ“Š Modelo de Machine Learning

### **Arquitetura da Rede Neural**
```
Input Layer (10 features) 
    â†“
Dense Layer (128 neurons) + ReLU + Dropout(30%)
    â†“  
Dense Layer (64 neurons) + ReLU + Dropout(30%)
    â†“
Dense Layer (32 neurons) + ReLU + Dropout(30%)
    â†“
Output Layer (1 neuron) + Sigmoid
```

### **CaracterÃ­sticas TÃ©cnicas**
- ğŸ¯ **Objetivo**: ClassificaÃ§Ã£o binÃ¡ria (Bom/Ruim pagador)
- ğŸ”„ **Otimizador**: Adam (learning_rate=0.001)
- ğŸ“‰ **Loss Function**: Binary Crossentropy
- ğŸƒ **Ã‰pocas**: 500 com validaÃ§Ã£o 30%/70%
- ğŸ“Š **SeleÃ§Ã£o**: RFE para top 10 features
- ğŸ² **Seed**: 42 (reprodutibilidade)

### **Pipeline de Dados**
1. **ExtraÃ§Ã£o**: Query SQL complexa juntando 4 tabelas
2. **Limpeza**: Tratamento de nulos e correÃ§Ã£o fuzzy
3. **Feature Engineering**: ProporÃ§Ã£o solicitado/total
4. **NormalizaÃ§Ã£o**: StandardScaler para numÃ©ricas
5. **CodificaÃ§Ã£o**: LabelEncoder para categÃ³ricas
6. **SeleÃ§Ã£o**: RFE para otimizaÃ§Ã£o de features

## ğŸ”® PrÃ³ximos Passos e Melhorias

### **ğŸš€ Desenvolvimentos Futuros**
- **Hyperparameter Tuning**: Grid Search e Bayesian Optimization
- **Model Ensemble**: CombinaÃ§Ã£o Random Forest + Neural Network
- **Monitoramento MLOps**: Drift detection e retraining automÃ¡tico
- **A/B Testing**: Framework para testar novos modelos

### **ğŸ—ï¸ Infraestrutura**
- **ContainerizaÃ§Ã£o**: Docker para deployment
- **CI/CD Pipeline**: GitHub Actions para automaÃ§Ã£o
- **Logging & Monitoring**: Prometheus + Grafana
- **Load Balancer**: Nginx para alta disponibilidade

### **ğŸ“ˆ Features AvanÃ§adas**
- **Dashboard Executivo**: MÃ©tricas de negÃ³cio em tempo real
- **IntegraÃ§Ã£o Externa**: Bureau de crÃ©dito e Open Banking
- **Modelo Temporal**: AnÃ¡lise de sÃ©rie temporal para sazonalidade
- **Explicabilidade AvanÃ§ada**: SHAP values e feature importance

### **ğŸ”’ Compliance & SeguranÃ§a**
- **LGPD/GDPR**: AnonimizaÃ§Ã£o e direito ao esquecimento
- **Auditoria**: Log de todas as decisÃµes
- **Bias Detection**: Fairness em decisÃµes de crÃ©dito
- **Security**: AutenticaÃ§Ã£o OAuth2 e criptografia

---

## ğŸ‘¨â€ğŸ’» Sobre o Projeto

Este projeto representa uma implementaÃ§Ã£o completa de um sistema de anÃ¡lise de crÃ©dito utilizando as melhores prÃ¡ticas de Machine Learning e Engenharia de Software. Foi desenvolvido com foco em:

- âœ… **Qualidade de CÃ³digo**: DocumentaÃ§Ã£o, testes e estrutura modular
- âœ… **Escalabilidade**: Arquitetura preparada para produÃ§Ã£o  
- âœ… **Explicabilidade**: TransparÃªncia nas decisÃµes algorÃ­tmicas
- âœ… **ExperiÃªncia do UsuÃ¡rio**: Interface intuitiva e responsiva

**ContribuiÃ§Ãµes sÃ£o bem-vindas!** ğŸ¤

---

*Desenvolvido por **TonFLY** | [GitHub](https://github.com/TonFLY) | 2025*

